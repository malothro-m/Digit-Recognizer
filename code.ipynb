{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyyrHn5TPUzJVXs9hLvuaz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malothro-m/Digit-Recognizer/blob/main/code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Set up Google Colab environment\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Dense, LSTM, Bidirectional, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 2: Load and Prepare the MNIST Dataset\n",
        "def load_multi_digit_mnist():\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "    num_digits = 3\n",
        "    x_train_multi, y_train_multi = [], []\n",
        "    for i in range(len(x_train) - num_digits):\n",
        "        stacked_images = np.hstack(x_train[i:i+num_digits])\n",
        "        stacked_images = np.expand_dims(stacked_images, axis=-1)\n",
        "        x_train_multi.append(stacked_images)\n",
        "        stacked_labels = np.array([y_train[i], y_train[i+1], y_train[i+2]])\n",
        "        y_train_multi.append(stacked_labels)\n",
        "\n",
        "    x_train_multi = np.array(x_train_multi)\n",
        "    y_train_multi = np.array(y_train_multi)\n",
        "\n",
        "    x_test_multi, y_test_multi = [], []\n",
        "    for i in range(len(x_test) - num_digits):\n",
        "        stacked_images = np.hstack(x_test[i:i+num_digits])\n",
        "        stacked_images = np.expand_dims(stacked_images, axis=-1)\n",
        "        x_test_multi.append(stacked_images)\n",
        "        stacked_labels = np.array([y_test[i], y_test[i+1], y_test[i+2]])\n",
        "        y_test_multi.append(stacked_labels)\n",
        "\n",
        "    x_test_multi = np.array(x_test_multi)\n",
        "    y_test_multi = np.array(y_test_multi)\n",
        "\n",
        "    return x_train_multi, y_train_multi, x_test_multi, y_test_multi\n",
        "\n",
        "x_train, y_train, x_test, y_test = load_multi_digit_mnist()\n",
        "\n",
        "# Step 3: Define the CTC Loss Function\n",
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    return tf.keras.backend.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        "\n",
        "# Step 4: Build the CRNN Model\n",
        "def build_crnn_model(input_shape=(28, 28*3, 1), num_classes=10):\n",
        "    input_data = Input(name=\"input\", shape=input_shape)\n",
        "    cnn = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input_data)\n",
        "    cnn = MaxPooling2D(pool_size=(2, 2))(cnn)\n",
        "    cnn = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(cnn)\n",
        "    cnn = MaxPooling2D(pool_size=(2, 2))(cnn)\n",
        "\n",
        "    reshaped_units = cnn.shape[1] * cnn.shape[2]\n",
        "    cnn = Reshape(target_shape=(reshaped_units, cnn.shape[-1]))(cnn)\n",
        "\n",
        "    lstm = Bidirectional(LSTM(128, return_sequences=True))(cnn)\n",
        "    lstm = Bidirectional(LSTM(128, return_sequences=True))(lstm)\n",
        "    dense = Dense(num_classes + 1, activation=\"softmax\")(lstm)  # +1 for CTC blank label\n",
        "\n",
        "    labels = Input(name=\"labels\", shape=[None], dtype=\"float32\")\n",
        "    input_length = Input(name=\"input_length\", shape=[1], dtype=\"int64\")\n",
        "    label_length = Input(name=\"label_length\", shape=[1], dtype=\"int64\")\n",
        "    ctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name=\"ctc\")(\n",
        "        [dense, labels, input_length, label_length]\n",
        "    )\n",
        "\n",
        "    model = Model(inputs=[input_data, labels, input_length, label_length], outputs=ctc_loss)\n",
        "    model.compile(optimizer=Adam(), loss={\"ctc\": lambda y_true, y_pred: y_pred})\n",
        "    prediction_model = Model(inputs=input_data, outputs=dense)\n",
        "\n",
        "    return model, prediction_model\n",
        "\n",
        "model, prediction_model = build_crnn_model()\n",
        "print(\"Model built successfully!\")\n",
        "\n",
        "# Step 5: Define Data Augmentation with Additional CTC Inputs\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class CTCAugmentedDataGenerator(Sequence):\n",
        "    def __init__(self, images, labels, batch_size=32, num_classes=10):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.datagen = ImageDataGenerator(rotation_range=5, width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.images[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "\n",
        "        augmented_images = next(self.datagen.flow(batch_x, batch_size=self.batch_size, shuffle=False))\n",
        "        input_length = np.ones((self.batch_size, 1)) * (augmented_images.shape[1] // 2)\n",
        "        label_length = np.ones((self.batch_size, 1)) * 3\n",
        "\n",
        "        batch_y = np.array(batch_y)\n",
        "        ctc_dummy_output = np.zeros(self.batch_size)\n",
        "        # Convert outputs to tf.Tensor format for compatibility\n",
        "        return (  # Changed from [ to ( to return a tuple\n",
        "            (tf.convert_to_tensor(augmented_images, dtype=tf.float32),\n",
        "             tf.convert_to_tensor(batch_y, dtype=tf.float32),\n",
        "             tf.convert_to_tensor(input_length, dtype=tf.float32),\n",
        "             tf.convert_to_tensor(label_length, dtype=tf.float32)),\n",
        "            tf.convert_to_tensor(ctc_dummy_output, dtype=tf.float32)\n",
        "        ) # Changed from ] to ) to return a tuple\n",
        "\n",
        "batch_size = 32\n",
        "train_gen = CTCAugmentedDataGenerator(x_train, y_train, batch_size=batch_size)\n",
        "\n",
        "# Step 6: Train the Model\n",
        "epochs = 10\n",
        "input_length_test = np.ones((len(x_test), 1)) * (x_test.shape[2] // 4)\n",
        "label_length_test = np.ones((len(y_test), 1)) * 3\n",
        "\n",
        "# Ensure all inputs are converted to tf.Tensor format\n",
        "x_test_tensor = tf.convert_to_tensor(x_test, dtype=tf.float32)\n",
        "y_test_tensor = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
        "input_length_test_tensor = tf.convert_to_tensor(input_length_test, dtype=tf.float32)\n",
        "label_length_test_tensor = tf.convert_to_tensor(label_length_test, dtype=tf.float32)\n",
        "\n",
        "model.fit(\n",
        "    train_gen,\n",
        "    epochs=epochs,\n",
        "    validation_data=(\n",
        "        [x_test_tensor, y_test_tensor, input_length_test_tensor, label_length_test_tensor],\n",
        "        tf.convert_to_tensor(np.zeros(len(x_test)), dtype=tf.float32),\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Step 7: Evaluate and Predict\n",
        "def decode_predictions(preds):\n",
        "    input_len = np.ones(preds.shape[0]) * preds.shape[1]\n",
        "    decoded = tf.keras.backend.ctc_decode(preds, input_length=input_len, greedy=True)[0][0]\n",
        "    return tf.keras.backend.get_value(decoded)\n",
        "\n",
        "test_preds = prediction_model.predict(x_test)\n",
        "decoded_preds = decode_predictions(test_preds)\n",
        "\n",
        "for i in range(5):\n",
        "    plt.imshow(x_test[i].reshape(28, 28 * 3), cmap=\"gray\")\n",
        "    plt.title(f\"Predicted: {''.join(map(str, decoded_preds[i]))}\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Byml494jqdH",
        "outputId": "1e9a9f2b-363a-47a9-ceb1-ca9069bf397d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model built successfully!\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1874/1874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2202s\u001b[0m 1s/step - loss: 8.2651 - val_loss: 5.5743\n",
            "Epoch 2/10\n",
            "\u001b[1m 444/1874\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26:34\u001b[0m 1s/step - loss: 5.8272"
          ]
        }
      ]
    }
  ]
}